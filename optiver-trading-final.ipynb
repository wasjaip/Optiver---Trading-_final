{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":57891,"databundleVersionId":7056235,"sourceType":"competition"},{"sourceId":6497264,"sourceType":"datasetVersion","datasetId":3755317},{"sourceId":7090651,"sourceType":"datasetVersion","datasetId":4085969},{"sourceId":7230606,"sourceType":"datasetVersion","datasetId":3857034},{"sourceId":7335130,"sourceType":"datasetVersion","datasetId":3856023}],"dockerImageVersionId":30674,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"papermill":{"default_parameters":{},"duration":201.394075,"end_time":"2023-12-17T01:30:48.787542","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-12-17T01:27:27.393467","version":"2.4.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"–ü—Ä–∏–≤–µ—Ç –≤—Å–µ–º! üëã –Ø —Ä–∞–¥ –ø–æ–¥–µ–ª–∏—Ç—å—Å—è —Å –≤–∞–º–∏  —Ä–µ—à–µ–Ω–∏–µ–º,–ø–æ–ª—É—á–∏–ª –ø–µ—Ä–≤—É—é –±—Ä–æ–Ω–∑–æ–≤—É—é –º–µ–¥–∞–ª—å: https://www.kaggle.com/competitions/optiver-trading-at-the-close\n\n–í —ç—Ç–æ—Ç —Ä–∞–∑ —è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∞–Ω—Å–∞–º–±–ª—è –∏–∑ XGBoost –∏ Light Gradient Boosted, –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —É–≤–µ–ª–∏—á–∏–≤–∞—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è. –ü–æ–¥—Ö–æ–¥ –≤–∫–ª—é—á–∞–ª –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ 160 –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –∞ –Ω–∞—á–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –±—ã–ª–∏ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω—ã –∏–∑ –∏—Å–ø—ã—Ç–∞–Ω–∏–π Optuna, –ø–æ—Ö–æ–∂–∏—Ö –Ω–∞ —Ç–µ, —á—Ç–æ  –º–æ–∂–µ—Ç–µ –Ω–∞–π—Ç–∏ –≤ –º–æ–µ–º GitHub.\n\n–≠—Ç–æ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–µ –±—ã–ª–æ –Ω–µ–≤–µ—Ä–æ—è—Ç–Ω–æ —É–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω—ã–º, –∏ —Ä–∞–±–æ—Ç–∞  –ø—Ä–∏–Ω–µ—Å–ª–∞ –º–Ω–µ –æ–≥—Ä–æ–º–Ω–æ–µ —É–¥–æ–≤–æ–ª—å—Å—Ç–≤–∏–µ üòä. –Ø –≤—ã–Ω–µ—Å –º–∞—Å—Å—É –∑–Ω–∞–Ω–∏–π –æ –±–∞–∑–æ–≤—ã—Ö –ø—Ä–∏–Ω—Ü–∏–ø–∞—Ö, —É—Å–∫–æ—Ä–µ–Ω–∏–∏ –∫–æ–¥–∞ –∏ —Å–æ—Å—Ä–µ–¥–æ—Ç–æ—á–µ–Ω–∏–∏ –≤–Ω–∏–º–∞–Ω–∏—è –Ω–∞ –º–µ—Ç–æ–¥–∏–∫–∞—Ö, –∫–æ—Ç–æ—Ä—ã–µ –æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—Ç –Ω–∞–∏–ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, –≤–º–µ—Å—Ç–æ —Ç–æ–≥–æ —á—Ç–æ–±—ã —Å–ª–∏—à–∫–æ–º —É–≥–ª—É–±–ª—è—Ç—å—Å—è –≤ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ. –û–≥—Ä–æ–º–Ω–æ–µ —Å–ø–∞—Å–∏–±–æ –≤—Å–µ–º!\n","metadata":{}},{"cell_type":"markdown","source":"## —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–∞–∫–µ—Ç–æ–≤ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è Python, –∏—Å–ø–æ–ª—å–∑—É—è —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã —É—Å—Ç–∞–Ω–æ–≤–∫–∏ (wheels) –∏  –≤—ã–≤–æ–¥","metadata":{}},{"cell_type":"code","source":"%%time \n\n# –Ø –∏–º–ø–æ—Ä—Ç–∏—Ä—É—é –º–æ–¥—É–ª—å –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –≤—ã–≤–æ–¥–∞ –≤ IPython, —á—Ç–æ–±—ã –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä–æ–≤–∞—Ç—å, —á—Ç–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è –≤ –≤—ã–≤–æ–¥–µ —è—á–µ–π–∫–∏\nfrom IPython.display import clear_output\n\n# –ò–º–ø–æ—Ä—Ç–∏—Ä—É—é –º–æ–¥—É–ª—å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–±–æ—Ä—â–∏–∫–æ–º –º—É—Å–æ—Ä–∞, —á—Ç–æ–±—ã –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏\nimport gc\n\n# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é –ø–∞–∫–µ—Ç—ã LightGBM, XGBoost –∏ CatBoost, –∏—Å–ø–æ–ª—å–∑—É—è –ª–æ–∫–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã .whl, –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ, –Ω–∞–ø—Ä–∏–º–µ—Ä, –∏–∑ Kaggle Datasets\n# –û–ø—Ü–∏—è '-q' –ø–æ–∑–≤–æ–ª—è–µ—Ç –º–Ω–µ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∏—Ö –≤ —Ç–∏—Ö–æ–º —Ä–µ–∂–∏–º–µ, —á—Ç–æ–±—ã –Ω–µ –∑–∞—Å–æ—Ä—è—Ç—å –≤—ã–≤–æ–¥ –ª–∏—à–Ω–µ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π\n!pip install /kaggle/input/lightgbm410/lightgbm-4.1.0-py3-none-manylinux_2_28_x86_64.whl -q\n!pip install /kaggle/input/xgboost-2-0-0-whl/xgboost-2.0.2-py3-none-manylinux2014_x86_64.whl -q\n!pip install /kaggle/input/catboost-1-2-2/catboost-1.2.2-cp310-cp310-manylinux2014_x86_64.whl -q\n\n# –ü–æ—Å–ª–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ —è –æ—á–∏—â–∞—é –≤—ã–≤–æ–¥ —è—á–µ–π–∫–∏, —á—Ç–æ–±—ã —Å–¥–µ–ª–∞—Ç—å –µ–≥–æ –±–æ–ª–µ–µ —á–∏—Å—Ç—ã–º –∏ –∞–∫–∫—É—Ä–∞—Ç–Ω—ã–º\nclear_output()\n\n# –ü–µ—á–∞—Ç–∞—é –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É, —á—Ç–æ–±—ã –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è %%time –æ—Ç–æ–±—Ä–∞–∑–∏–ª–æ—Å—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ\nprint()\n","metadata":{"papermill":{"duration":113.52152,"end_time":"2023-12-17T01:29:25.392635","exception":false,"start_time":"2023-12-17T01:27:31.871115","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-18T08:31:09.940765Z","iopub.execute_input":"2023-12-18T08:31:09.941018Z","iopub.status.idle":"2023-12-18T08:33:05.957884Z","shell.execute_reply.started":"2023-12-18T08:31:09.940994Z","shell.execute_reply":"2023-12-18T08:33:05.956701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏","metadata":{}},{"cell_type":"code","source":"%%time \n\n# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–æ–¥—É–ª–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –¥–∞–Ω–Ω—ã–º–∏, –º–∞—à–∏–Ω–Ω—ã–º –æ–±—É—á–µ–Ω–∏–µ–º –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –∫–æ–¥–∞\nimport ctypes, gc, os, time, warnings, joblib, lightgbm as lgb, catboost, numpy as np, pandas as pd, polars as pl\nfrom warnings import simplefilter\n\n# –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –¥–ª—è –±–æ–ª–µ–µ —á–∏—Å—Ç–æ–≥–æ –≤—ã–≤–æ–¥–∞\nwarnings.filterwarnings(\"ignore\")\nsimplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n\n# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∫–æ–º–±–∏–Ω–∞—Ü–∏—è–º–∏, –ø–µ—á–∞—Ç–∏ –∏ –º–æ–¥–µ–ª—è–º–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è\nfrom itertools import combinations\nfrom pprint import pprint\nfrom catboost import CatBoostRegressor, EShapCalcType, EFeaturesSelectionAlgorithm\nfrom xgboost import XGBRegressor\n\n# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥—É–ª–∏ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π\nfrom numba import njit, prange, jit\n\n# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–µ–π –∏ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import KFold, TimeSeriesSplit\n\n# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è —Ü–≤–µ—Ç–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞ –≤ –∫–æ–Ω—Å–æ–ª—å\nfrom colorama import Fore, Style, init\n\n# –û—á–∏—â–∞–µ–º –≤—ã–≤–æ–¥ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –∫–æ–º–∞–Ω–¥ –≤ Jupyter notebook\nclear_output()\n\n# –í—ã–≤–æ–¥–∏–º —Ç–µ–∫—É—â–∏–µ –≤–µ—Ä—Å–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫ CatBoost –∏ LightGBM\nprint(f\"\\nCurrent CatBoost version = {catboost.__version__}\")\nprint(f\"Current LightGBM version = {lgb.__version__}\\n\")\n\n# –í—ã–∑—ã–≤–∞–µ–º —Å–±–æ—Ä—â–∏–∫ –º—É—Å–æ—Ä–∞ –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º–æ–π –ø–∞–º—è—Ç–∏\ngc.collect()\nprint()  # –ü–µ—á–∞—Ç–∞–µ–º –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –¥–ª—è –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –≤—ã–≤–æ–¥–∞\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":8.513045,"end_time":"2023-12-17T01:29:33.915802","exception":false,"start_time":"2023-12-17T01:29:25.402757","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-18T08:33:05.960191Z","iopub.execute_input":"2023-12-18T08:33:05.96067Z","iopub.status.idle":"2023-12-18T08:33:13.728662Z","shell.execute_reply.started":"2023-12-18T08:33:05.960631Z","shell.execute_reply":"2023-12-18T08:33:13.727745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \n\n# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤–µ—Ä—Å–∏—é –∏ —Ñ–ª–∞–≥ –≤—ã–≤–æ–¥–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏\nversion = 27\ninference_flag = 3\n\n# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ñ–ª–∞–≥–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∑–Ω–∞—á–µ–Ω–∏—è inference_flag\nif inference_flag == 0:\n    # –†–µ–∂–∏–º –æ—Ñ–ª–∞–π–Ω-—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ –±–µ–∑ –≤—ã–≤–æ–¥–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –æ—Ç–ª–∞–¥–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏\n    is_offline = True\n    is_train = True\n    is_infer = False\n    debug_flag = False\n    \nelif inference_flag == 1:\n    # –†–µ–∂–∏–º –æ–Ω–ª–∞–π–Ω-—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ —Å –≤—ã–≤–æ–¥–æ–º –æ—Ç–ª–∞–¥–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏\n    is_offline = False\n    is_train = True\n    is_infer = True\n    debug_flag = True\n    \nelif inference_flag == 2:\n    # –†–µ–∂–∏–º –æ–Ω–ª–∞–π–Ω-—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ –±–µ–∑ –≤—ã–≤–æ–¥–∞ –æ—Ç–ª–∞–¥–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏\n    is_offline = False\n    is_train = True\n    is_infer = True\n    debug_flag = False\n    \nelif inference_flag == 3:\n    # –†–µ–∂–∏–º –æ–Ω–ª–∞–π–Ω-–∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ (–≤—ã–≤–æ–¥–∞) —Å –æ—Ç–ª–∞–¥–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π\n    is_offline = False\n    is_train = False\n    is_infer = True\n    debug_flag = True\n    \n# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏\nmax_lookback = np.nan  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –Ω–∞–∑–∞–¥, –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –Ω–µ –∑–∞–¥–∞–Ω–æ\nsplit_day = 435        # –î–µ–Ω—å –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –∏ —Ç–µ—Å—Ç–æ–≤—ã–µ\n\n# –û—Ç–ª–∞–¥–æ—á–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –≤ —Ç–µ–∫—É—â–µ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–µ\nstreaming = False\ncheck_code = False\ntest_runtime = False\n\n# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∞–Ω—Å–∞–º–±–ª–µ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è\nuse_lgb = True  # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ LightGBM\nuse_cat = True  # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ CatBoost\nuse_xgb = False  # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ XGBoost –Ω–µ –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–æ\n\n# –í–µ—Å–∞ –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏ –≤ –∞–Ω—Å–∞–º–±–ª–µ\nlgb_weight = 0.50\ncat_weight = 0.50\nxgb_weight = 0\n\n# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏\nis_refit = True      # –ù—É–∂–Ω–æ –ª–∏ –ø—Ä–æ–≤–æ–¥–∏—Ç—å –ø–æ–≤—Ç–æ—Ä–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ\nnb_refits = 12       # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –æ–±—É—á–µ–Ω–∏–π\nfreq_refits = 6      # –ß–∞—Å—Ç–æ—Ç–∞ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –æ–±—É—á–µ–Ω–∏–π\nwd_refits = 450      # –í—Ä–µ–º–µ–Ω–Ω–æ–µ –æ–∫–Ω–æ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è\n\n# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤\npostprocess = \"NA\"   # –¢–∏–ø –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∏, –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\n\n# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ —Å —Ü–µ–ª—å—é —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è —Å—É–º–º—ã –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ —Ä–∞–≤–Ω–æ–π –Ω—É–ª—é\ndef zero_sum(prices, volumes):\n    std_error = np.sqrt(volumes)\n    step = np.sum(prices) / np.sum(std_error)\n    out = prices - std_error * step\n    return out\n\n# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–µ—á–∞—Ç–∏ —Ü–≤–µ—Ç–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –≤ –∫–æ–Ω—Å–æ–ª–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ colorama\ndef PrintColor(text:str, color=Fore.BLUE, style=Style.BRIGHT):\n    \"Prints colored outputs using colorama using a text F-string\"\n    print(style + color + text + Style.RESET_ALL)\n\n# –í—ã–∑—ã–≤–∞–µ–º —Å–±–æ—Ä—â–∏–∫ –º—É—Å–æ—Ä–∞ –¥–ª—è –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏—è –ø–∞–º—è—Ç–∏\ngc.collect()\nprint()  # –ü–µ—á–∞—Ç–∞–µ–º –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –¥–ª—è –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –≤—ã–≤–æ–¥–∞\n","metadata":{"execution":{"iopub.status.busy":"2023-12-18T08:33:13.730449Z","iopub.execute_input":"2023-12-18T08:33:13.730884Z","iopub.status.idle":"2023-12-18T08:33:13.833658Z","shell.execute_reply.started":"2023-12-18T08:33:13.730837Z","shell.execute_reply":"2023-12-18T08:33:13.832764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **–î–µ—Ç–∞–ª–∏ –≤–µ—Ä—Å–∏–∏**","metadata":{}},{"cell_type":"markdown","source":"| Version | Description | Date| Refits x Freq| Best LB Score| Post-processing|\n|:-:|---|:-:|:-:|:-:|:-:|\n|27 | * 170 features <br> * Alternating refits between LGBM, CB <br> * Refitting window = 470 dates <br> * 60-40 ensemble weights | 17Dec2023 | 12x6| 5.3387|NA|\n|27 | * 170 features <br> * Alternating refits between LGBM, CB <br> * Refitting window = 500 dates <br> * 60-40 ensemble weights | 18Dec2023 | 12x6| |NA|\n|27 | * 170 features <br> * Alternating refits between LGBM, CB <br> * Refitting window = 450 dates <br> * 50-50 ensemble weights | 18Dec2023 | 12x6| |NA|","metadata":{}},{"cell_type":"markdown","source":"# **–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞**","metadata":{}},{"cell_type":"markdown","source":"–û–±—Ä–∞–±–æ—Ç–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã, –¥–æ–±–∞–≤–ª—è—è –ª–∞–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ü–µ–ª–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ 'stock_id' –∏ 'seconds_in_bucket', –Ω–æ —Å–¥–≤–∏–≥–∞—è 'date_id' –Ω–∞ –æ–¥–∏–Ω, –¥–≤–∞ –∏ —Ç—Ä–∏ –¥–Ω—è –≤–ø–µ—Ä–µ–¥. –ü–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤—ã–ø–æ–ª–Ω—è–µ—à—å –æ—á–∏—Å—Ç–∫—É –ø–∞–º—è—Ç–∏ –∏ —É–¥–∞–ª—è–µ—à—å —Å—Ç—Ä–æ–∫–∏ —Å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏. –¢–∞–∫–∂–µ  —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –¥–∞–Ω–Ω—ã—Ö –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ —Ñ–ª–∞–≥–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–æ–¥–∞. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ ctypes.CDLL(\"libc.so.6\").malloc_trim(0) –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–æ –¥–ª—è –±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–π –æ—á–∏—Å—Ç–∫–∏ –ø–∞–º—è—Ç–∏ –≤ —Å—Ä–µ–¥–µ Linux.","metadata":{}},{"cell_type":"code","source":"%%time \n\n# –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ CSV-—Ñ–∞–π–ª–∞ –≤ DataFrame\ndf = pd.read_csv(\"/kaggle/input/optiver-trading-at-the-close/train.csv\")\n\n# –°–æ–∑–¥–∞–µ–º –ª–∞–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ü–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ (targets) –¥–ª—è –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π\n# –ó–¥–µ—Å—å —Å–æ–∑–¥–∞–µ—Ç—Å—è DataFrame last_targets —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ —Ü–µ–ª–µ–π (lagged targets)\n\n# –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –∏ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫—É —Å —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π\nlast_targets = df[[\"stock_id\", \"date_id\", \"seconds_in_bucket\", \"target\"]].rename(columns={\"target\": \"prev_1_target\"})\n# –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º date_id –Ω–∞ 1, —á—Ç–æ–±—ã —Å–¥–≤–∏–Ω—É—Ç—å—Å—è –Ω–∞ –æ–¥–∏–Ω –¥–µ–Ω—å –≤–ø–µ—Ä–µ–¥\nlast_targets[\"date_id\"] = last_targets[\"date_id\"] + 1\n# –û–±—ä–µ–¥–∏–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π DataFrame —Å –ª–∞–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏\ndf = df.merge(last_targets, on=[\"stock_id\", \"date_id\", \"seconds_in_bucket\"], how=\"left\")\n# –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π DataFrame –∏ –æ—á–∏—â–∞–µ–º –ø–∞–º—è—Ç—å\ndel last_targets\ngc.collect()\n# –ü–æ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º —Å–∏—Å—Ç–µ–º–µ –æ—Å–≤–æ–±–æ–¥–∏—Ç—å –ø–∞–º—è—Ç—å\nctypes.CDLL(\"libc.so.6\").malloc_trim(0)\n\n# –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ –¥–æ–±–∞–≤–ª—è–µ–º –≤—Ç–æ—Ä—É—é –ª–∞–≥–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Ü–µ–ª—å, —Å–¥–≤–∏–≥–∞—è—Å—å –Ω–∞ –¥–≤–∞ –¥–Ω—è\nlast_targets_2 = df[[\"stock_id\", \"date_id\", \"seconds_in_bucket\", \"target\"]].rename(columns={\"target\": \"prev_2_target\"})\nlast_targets_2[\"date_id\"] = last_targets_2[\"date_id\"] + 2\ndf = df.merge(last_targets_2, on=[\"stock_id\", \"date_id\", \"seconds_in_bucket\"], how=\"left\")\ndel last_targets_2\ngc.collect()\nctypes.CDLL(\"libc.so.6\").malloc_trim(0)\n\n# –î–æ–±–∞–≤–ª—è–µ–º —Ç—Ä–µ—Ç—å—é –ª–∞–≥–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Ü–µ–ª—å, —Å–¥–≤–∏–≥–∞—è—Å—å –Ω–∞ —Ç—Ä–∏ –¥–Ω—è\nlast_targets_3 = df[[\"stock_id\", \"date_id\", \"seconds_in_bucket\", \"target\"]].rename(columns={\"target\": \"prev_3_target\"})\nlast_targets_3[\"date_id\"] = last_targets_3[\"date_id\"] + 3\ndf = df.merge(last_targets_3, on=[\"stock_id\", \"date_id\", \"seconds_in_bucket\"], how=\"left\")\ndel last_targets_3\ngc.collect()\nctypes.CDLL(\"libc.so.6\").malloc_trim(0)\n\n# –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ –∫–∞–∫–∏–µ-–ª–∏–±–æ –∏–∑ —Ü–µ–ª–µ–π (target –∏–ª–∏ –ª–∞–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ) –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç\ndf = df.dropna(subset=[\"target\", \"prev_1_target\", \"prev_2_target\", \"prev_3_target\"], how=\"any\")\n# –°–±—Ä–∞—Å—ã–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å –¥–ª—è —á–∏—Å—Ç–æ—Ç—ã –¥–∞–Ω–Ω—ã—Ö\ndf.reset_index(drop=True, inplace=True)\n# –í—ã–≤–æ–¥–∏–º —Ä–∞–∑–º–µ—Ä –Ω–æ–≤–æ–≥–æ DataFrame\nprint(df.shape)\n\n# –ï—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —Ñ–ª–∞–≥ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–æ–¥–∞, –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º DataFrame –¥–∞–Ω–Ω—ã–º–∏, –Ω–∞—á–∏–Ω–∞—è —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ –¥–Ω—è\nif check_code:\n    df = df[df.date_id >= 375].reset_index(drop=True)\n\n# –°–Ω–æ–≤–∞ –≤—ã–∑—ã–≤–∞–µ–º —Å–±–æ—Ä—â–∏–∫ –º—É—Å–æ—Ä–∞ –∏ –ø–æ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º —Å–∏—Å—Ç–µ–º–µ –æ—Å–≤–æ–±–æ–¥–∏—Ç—å –ø–∞–º—è—Ç—å\ngc.collect()\nprint()\nctypes.CDLL(\"libc.so.6\").malloc_trim(0)\n","metadata":{"papermill":{"duration":18.963694,"end_time":"2023-12-17T01:29:52.959514","exception":false,"start_time":"2023-12-17T01:29:33.99582","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-18T08:33:13.835845Z","iopub.execute_input":"2023-12-18T08:33:13.836125Z","iopub.status.idle":"2023-12-18T08:33:40.392852Z","shell.execute_reply.started":"2023-12-18T08:33:13.836101Z","shell.execute_reply":"2023-12-18T08:33:40.391844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **–î–æ–±–∞–≤–∏–º –Ω–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã**","metadata":{"papermill":{"duration":0.010746,"end_time":"2023-12-17T01:30:21.153362","exception":false,"start_time":"2023-12-17T01:30:21.142616","status":"completed"},"tags":[]}},{"cell_type":"code","source":"%%time \n\n####################################################################\n# Memory reduction:-\ndef reduce_mem_usage(df, verbose=0):\n    \"\"\"\n    Iterate through all numeric columns of a dataframe and modify the data type to reduce memory usage.\n    \"\"\";\n\n    start_mem = df.memory_usage().sum() / 1024**2\n\n    for col in df.columns:\n        col_type = df[col].dtype\n\n        if col_type != object and col != \"target\":\n            c_min = df[col].min()\n            c_max = df[col].max()\n\n            if str(col_type)[:3] == \"int\" or str(col_type)[:4] == \"uint\":\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float32)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float32)\n    return df;\n\n####################################################################\n# RSI calculation:-\ndef calculate_rsi(prices, period= 14):\n    rsi_values = np.zeros_like(prices);\n    for col in prange(prices.shape[1]):\n        price_data = prices[:, col];\n        delta      = np.zeros_like(price_data);\n        delta[1:]  = price_data[1:] - price_data[:-1];\n        gain       = pd.Series(np.where(delta > 0, delta, 0));\n        loss       = pd.Series(np.where(delta < 0, -delta, 0));\n        avg_gain   = gain.rolling(window=period,\n                                  min_periods=period).mean(engine='numba', engine_kwargs={\"parallel\": True});\n        avg_loss   = loss.rolling(window=period,\n                                  min_periods=period).mean(engine='numba', engine_kwargs={\"parallel\": True});\n        rs         = avg_gain / avg_loss;\n        rs         = rs.replace([np.inf, -np.inf], 1e-9);\n        rsi_values[:, col] = 100 - (100 / (1 + rs));\n    return rsi_values;\n\ndef generate_rsi(df):\n    # Define lists of price and size-related column names\n    prices = [\"reference_price\", \"far_price\", \"near_price\", \"ask_price\", \"bid_price\", \"wap\"];\n    sizes  = [\"matched_size\", \"bid_size\", \"ask_size\", \"imbalance_size\"];\n\n    for stock_id, values in df.groupby(['stock_id'])[prices]:\n        columns = [f'rsi_{col}' for col in values.columns];\n        data    = calculate_rsi(values.values);\n        df.loc[values.index, columns] = data;\n    return df;\n\ndef generate_all_features(df, global_ftre: dict,\n                          grouper_cols: list = ['stock_id'],\n                          roll_window : list = [1, 2, 3, 5, 10],\n                          ma_window   : list = [5, 10, 20],\n                          ewm_window  : list = [7, 30],\n                          wap_ftre_req: str = \"N\",\n                          **kwarg\n                          ):\n    \"\"\"\n    This function generates all secondary features for the model\n\n    Note:-\n    1. We make MACD, EWM and BBbands, ASHI index for WAP only\n    2. We make SMA for certain columns\n    3. We use global features also\n    \"\"\";\n\n    cols      = [c for c in df.columns if c not in [\"row_id\", \"time_id\"]];\n    df        = df[cols];\n    prices    = [\"reference_price\", \"far_price\", \"near_price\", \"ask_price\", \"bid_price\", \"wap\"];\n    sizes     = [\"matched_size\", \"bid_size\", \"ask_size\", \"imbalance_size\"];\n    roll_cols = ['matched_size', 'imbalance_size', 'reference_price',\n                 'ask_price', 'bid_price', 'ask_size', 'bid_size', 'wap', 'near_price', 'far_price']\n    ma_cols   = ['imbalance_size', 'reference_price', 'matched_size', 'wap'];\n    ewm_cols  = [\"wap\"];\n\n    df[\"imbalance_size\"] = df[\"imbalance_size\"] * df[\"imbalance_buy_sell_flag\"];\n    df[\"ratio_imb_mat\"] = df[\"imbalance_size\"] / df[\"matched_size\"];\n    df = df.drop(columns = [\"imbalance_buy_sell_flag\"]);\n\n    # Date and time calculation:-\n    df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60;\n    df[\"minute\"]  = df[\"seconds_in_bucket\"] // 60;\n\n    # Global feature calculation:-\n    for key, value in global_stock_id_feats.items():\n        df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict());\n\n    # RSI calculation:-\n    df = generate_rsi(df)\n\n    # General feature calculation:-\n    df[\"volume\"]              = df.eval(\"ask_size + bid_size\");\n    df[\"mid_price\"]           = df.eval(\"(ask_price + bid_price) / 2\");\n    df[\"liquidity_imbalance\"] = df.eval(\"(bid_size-ask_size)/(bid_size+ask_size)\");\n    df[\"matched_imbalance\"]   = df.eval(\"(imbalance_size-matched_size)/(matched_size+imbalance_size)\");\n    df[\"size_imbalance\"]      = df.eval(\"bid_size / ask_size\");\n    df['price_diff']          = df['reference_price'] - df['wap'];\n    df[\"imbalance_momentum\"]  = df.groupby(['stock_id'])['imbalance_size'].diff(periods=1) / df['matched_size'];\n    df[\"price_spread\"]        = df[\"ask_price\"] - df[\"bid_price\"];\n    df[\"spread_intensity\"]    = df.groupby(['stock_id'])['price_spread'].diff();\n    df['price_pressure']      = df['imbalance_size'] * (df['ask_price'] - df['bid_price']);\n    df['market_urgency']      = df['price_spread'] * df['liquidity_imbalance'];\n    df['depth_pressure']      = (df['ask_size'] - df['bid_size']) * (df['far_price'] - df['near_price']);\n    df['spread_depth_ratio']  = (df['ask_price'] - df['bid_price']) / (df['bid_size'] + df['ask_size']);\n    df['mid_price_movement']  = df.groupby([\"stock_id\"])['mid_price'].diff(periods=5).apply(lambda x: 1 if x > 0 else (-1 if x < 0 else 0));\n    df['micro_price']         = ((df['bid_price'] * df['ask_size']) + (df['ask_price'] * df['bid_size'])) / (df['bid_size'] + df['ask_size']);\n    df['relative_spread']     = (df['ask_price'] - df['bid_price']) / df['wap'];\n    df['high_volume']         = np.where(df['volume'] > df['global_median_size'], 1, 0);\n\n    # Combination feature calculation:-\n    for c in combinations(prices, 2):\n        df[f\"{c[0]}_{c[1]}_imb\"] = df.eval(f\"({c[0]} - {c[1]})/({c[0]} + {c[1]})\");\n\n    # Distribution feature calculation:-\n    for func in [\"mean\", \"std\", \"skew\", \"kurt\"]:\n        df[f\"all_prices_{func}\"] = df[prices].agg(func, axis=1)\n        df[f\"all_sizes_{func}\"] = df[sizes].agg(func, axis=1)\n\n    for col in roll_cols:\n        for window in roll_window:\n            df[f\"{col}_shift_{window}\"] = df.groupby('stock_id')[col].shift(window);\n            df[f\"{col}_ret_{window}\"]   = df.groupby('stock_id')[col].pct_change(window);\n\n    if wap_ftre_req == \"Y\":\n        for feature in ['imbalance_size', 'reference_price', 'matched_size', 'wap']:\n            for window_size in ma_window:\n                df[f'{feature}_rolling_mean_{window_size}'] = \\\n                df.groupby('stock_id')[feature].\\\n                transform(lambda x: x.rolling(window=window_size, min_periods=window_size).mean());\n            for window_size in [20]:\n                df[f'{feature}_rolling_std_{window_size}'] = \\\n                df.groupby('stock_id')[feature].\\\n                transform(lambda x: x.rolling(window=window_size, min_periods=window_size).std());\n\n            # WAP feature calculation:-\n            for feature in ['wap']:\n                short_window, long_window = 12, 26\n                for window in [short_window, long_window]:\n                    df[f'{feature}_ewm_{window}'] = \\\n                    df.groupby('stock_id')[feature].transform(lambda x: x.ewm(span=window).mean())\n\n            df[f'{feature}_vol_st'] = \\\n            df.groupby(['stock_id'])[feature].pct_change().transform(lambda x: x.rolling(window=short_window).std());\n            df[f'{feature}_std_st'] = \\\n            df.groupby(['stock_id'])[feature].transform(lambda x: x.rolling(window=short_window).std());\n\n            df[f'{feature}_macd'] = df[f'{feature}_ewm_{short_window}'] - df[f'{feature}_ewm_{long_window}'];\n\n            # Bollinger Bands calculation:-\n            df[f'{feature}_bollinger_upper'] =\\\n            df.groupby(['stock_id'])[feature].transform(lambda x: x.rolling(window=long_window).mean()) + \\\n            2 * df.groupby(['stock_id'])[feature].transform(lambda x: x.rolling(window=long_window).std());\n\n            df[f'{feature}_bollinger_lower'] = \\\n            df.groupby(['stock_id'])[feature].transform(lambda x: x.rolling(window=long_window).mean()) - \\\n            2 * df.groupby(['stock_id'])[feature].transform(lambda x: x.rolling(window=long_window).std());\n\n    return df.replace([np.inf, -np.inf], 0);\n\ngc.collect();\nprint();\nctypes.CDLL(\"libc.so.6\").malloc_trim(0);","metadata":{"execution":{"iopub.status.busy":"2023-12-18T08:33:40.394559Z","iopub.execute_input":"2023-12-18T08:33:40.395352Z","iopub.status.idle":"2023-12-18T08:33:40.539778Z","shell.execute_reply.started":"2023-12-18T08:33:40.395317Z","shell.execute_reply":"2023-12-18T08:33:40.538892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \n\n# –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –æ—Ñ—Ñ–ª–∞–π–Ω —Ä–µ–∂–∏–º–µ, —Ç–æ —Ä–∞–∑–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä—ã\nif is_offline:\n    # –î–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ –¥–Ω—è (split_day)\n    df_train = df[df[\"date_id\"] <= split_day]\n    # –î–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ —ç—Ç–æ–≥–æ –¥–Ω—è\n    df_valid = df[df[\"date_id\"] > split_day]\n    # –í—ã–≤–æ–¥–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—Ñ—Ñ–ª–∞–π–Ω —Ä–µ–∂–∏–º–µ –∏ —Ä–∞–∑–º–µ—Ä–∞—Ö –Ω–∞–±–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö\n    PrintColor(\"Offline mode\")\n    PrintColor(f\"train : {df_train.shape}, valid : {df_valid.shape}\")\nelse:\n    # –í –æ–Ω–ª–∞–π–Ω —Ä–µ–∂–∏–º–µ –≤–µ—Å—å –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏\n    df_train = df\n    PrintColor(\"Online mode\")\n\n# –ü–µ—á–∞—Ç–∞–µ–º –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –¥–ª—è –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –≤—ã–≤–æ–¥–∞\nprint()\n\n# –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –ø–∞–º—è—Ç—å, –≤—ã–∑—ã–≤–∞—è —Å–±–æ—Ä—â–∏–∫ –º—É—Å–æ—Ä–∞\ngc.collect()\n\n# –ü–æ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ –æ—á–∏—Å—Ç–∏—Ç—å –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—É—é –ø–∞–º—è—Ç—å\nctypes.CDLL(\"libc.so.6\").malloc_trim(0)\n","metadata":{"papermill":{"duration":0.01905,"end_time":"2023-12-17T01:30:22.542881","exception":false,"start_time":"2023-12-17T01:30:22.523831","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-18T08:33:40.541013Z","iopub.execute_input":"2023-12-18T08:33:40.541388Z","iopub.status.idle":"2023-12-18T08:33:40.647865Z","shell.execute_reply.started":"2023-12-18T08:33:40.541354Z","shell.execute_reply":"2023-12-18T08:33:40.646858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\n# –ï—Å–ª–∏ –º—ã –Ω–∞—Ö–æ–¥–∏–º—Å—è –≤ —Ä–µ–∂–∏–º–µ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏, –≤—ã—á–∏—Å–ª—è–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ stock_id\nif is_train:\n    # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å —Å –≥–ª–æ–±–∞–ª—å–Ω—ã–º–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–º–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏\n    global_stock_id_feats = {\n        \"median_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].median() + \n                       df_train.groupby(\"stock_id\")[\"ask_size\"].median(),\n        \"std_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].std() + \n                    df_train.groupby(\"stock_id\")[\"ask_size\"].std(),\n        \"ptp_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].max() - \n                    df_train.groupby(\"stock_id\")[\"bid_size\"].min(),\n        \"median_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].median() + \n                        df_train.groupby(\"stock_id\")[\"ask_price\"].median(),\n        \"std_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].std() + \n                     df_train.groupby(\"stock_id\")[\"ask_price\"].std(),\n        \"ptp_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].max() - \n                     df_train.groupby(\"stock_id\")[\"ask_price\"].min(),\n    }\n    \n    # –í —Ä–µ–∂–∏–º–µ –æ—Ñ—Ñ–ª–∞–π–Ω –≤—ã–ø–æ–ª–Ω—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —à–∞–≥–∏ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n    if is_offline:\n        # –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö\n        df_train = reduce_mem_usage(df_train)\n        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö\n        df_train_feats = generate_all_features(df_train, global_stock_id_feats)\n        # –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n        df_train_feats = reduce_mem_usage(df_train_feats)\n        print(\"Build Train Feats Finished.\")\n        # –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö\n        df_valid = reduce_mem_usage(df_valid)\n        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö\n        df_valid_feats = generate_all_features(df_valid, global_stock_id_feats)\n        # –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏\n        df_valid_feats = reduce_mem_usage(df_valid_feats)\n        print(\"Build Valid Feats Finished.\")\n        \n    else:\n        # –î–ª—è –æ–Ω–ª–∞–π–Ω —Ä–µ–∂–∏–º–∞ –≤—ã–ø–æ–ª–Ω—è–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Ç–æ–ª—å–∫–æ –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö\n        df_train = reduce_mem_usage(df_train)\n        df_train_feats = generate_all_features(df_train, global_stock_id_feats)\n        df_train_feats = reduce_mem_usage(df_train_feats)\n        print(\"Build Online Train Feats Finished.\");\n\n# –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –ø–∞–º—è—Ç—å, –≤—ã–∑—ã–≤–∞—è —Å–±–æ—Ä—â–∏–∫ –º—É—Å–æ—Ä–∞\ngc.collect()\n# –ü–µ—á–∞—Ç–∞–µ–º –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –¥–ª—è –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –≤—ã–≤–æ–¥–∞\nprint()\n# –ü–æ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ –æ—á–∏—Å—Ç–∏—Ç—å –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—É—é –ø–∞–º—è—Ç—å\nctypes.CDLL(\"libc.so.6\").malloc_trim(0)\n","metadata":{"papermill":{"duration":0.022768,"end_time":"2023-12-17T01:30:22.612233","exception":false,"start_time":"2023-12-17T01:30:22.589465","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-18T08:33:40.649211Z","iopub.execute_input":"2023-12-18T08:33:40.649558Z","iopub.status.idle":"2023-12-18T08:33:40.763867Z","shell.execute_reply.started":"2023-12-18T08:33:40.649528Z","shell.execute_reply":"2023-12-18T08:33:40.762914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **–¢—Ä–µ–Ω–∏—Ä—É–µ–º**","metadata":{}},{"cell_type":"code","source":"%%time \n\nif is_train:\n    feature_name = list(df_train_feats.columns)\n\n    lgb_params = {\n        'objective': 'mae', \n        'random_state': 42,\n        'device': 'gpu',\n        'boosting_type': 'gbdt', \n        'learning_rate': 0.015, \n        'max_depth': 12, \n        'n_estimators': 2000 if inference_flag == 0 else 2250, \n        'num_leaves': 300, \n        'reg_alpha': 0.005, \n        'reg_lambda': 0.001, \n        'colsample_bytree': 0.6, \n        'subsample': 0.875, \n        'min_child_samples': 128,\n    }\n    \n    \n    cat_params = dict(iterations=5042 if inference_flag == 0 else 5600,\n                      learning_rate=0.31464616673879614,\n                      depth=9,\n                      l2_leaf_reg=15.775786106845466,\n                      bootstrap_type='Bernoulli',\n                      subsample=0.9238669922301226,\n                      loss_function='MAE',\n                      eval_metric = 'MAE',\n                      metric_period=1000,\n                      task_type='GPU',\n                      allow_writing_files=False,\n                      random_state=42\n                      )\n    \n    xgb_params = {    'tree_method'           : 'hist',\n                      'device'                : \"cuda\",\n                      'objective'             : 'reg:absoluteerror',\n                      'n_estimators'          : 1800,\n                      'eval_metric'           : 'mae',\n                      'learning_rate'         : 0.018,\n                      'max_depth'             : 11,\n                      'colsample_bytree'      : 0.65,\n                      'reg_alpha'             : 0.001,\n                      'reg_lambda'            : 0.005,\n                      'verbosity'             : 0,\n                      'random_state'          : 42,\n                     }\n    \n    \n    print(f\"Feature length = {len(feature_name)}\")\n\n    # infer\n    df_train_target = df_train[\"target\"]\n    print(\"Infer Model Trainning.\")\n   \n    if use_lgb:\n        infer_lgb_params = lgb_params.copy()\n        print()\n        PrintColor(\"---> Infer LGB Params\", color=Fore.MAGENTA)\n        print(infer_lgb_params)\n        infer_lgb_model = lgb.LGBMRegressor(**infer_lgb_params)\n        infer_lgb_model.fit(df_train_feats[feature_name], df_train_target)\n        joblib.dump(infer_lgb_model, f'LGB_v{version}.model');\n    \n    if use_cat:\n        infer_cat_params = cat_params.copy()\n        print()\n        PrintColor(\"---> Infer Cat Params\", color=Fore.MAGENTA)\n        print(infer_cat_params)\n        infer_cat_model = CatBoostRegressor(**infer_cat_params)\n        infer_cat_model.fit(df_train_feats[feature_name], df_train_target)\n        joblib.dump(infer_cat_model, f'CAT_v{version}.model');\n        \n    if use_xgb:\n        infer_xgb_params = xgb_params.copy()\n        print()\n        PrintColor(\"---> Infer XGB Params\", color=Fore.MAGENTA)\n        print(infer_xgb_params)\n        infer_xgb_model = XGBRegressor(**infer_xgb_params)\n        infer_xgb_model.fit(df_train_feats[feature_name], df_train_target)\n        joblib.dump(infer_xgb_model, f'XGB_v{version}.model');\n\n    if is_offline:\n        if not streaming:\n            # offline predictions\n            df_valid_target = df_valid[\"target\"]\n\n            if use_lgb:\n                offline_predictions_lgb = infer_lgb_model.predict(df_valid_feats[feature_name])\n            if use_cat:\n                offline_predictions_cat = infer_cat_model.predict(df_valid_feats[feature_name])\n            if use_xgb:\n                offline_predictions_xgb = infer_xgb_model.predict(df_valid_feats[feature_name])\n\n            offline_predictions = None\n    \n            if use_lgb:\n                if offline_predictions is None:\n                    offline_predictions = (lgb_weight * offline_predictions_lgb)\n                else:\n                    offline_predictions += (lgb_weight * offline_predictions_lgb)\n\n            if use_cat:\n                if offline_predictions is None:\n                    offline_predictions = (cat_weight * offline_predictions_cat)\n                else:\n                    offline_predictions += (cat_weight * offline_predictions_cat)\n\n            if use_xgb:\n                if offline_predictions is None:\n                    offline_predictions = (xgb_weight * offline_predictions_xgb)\n                else:\n                    offline_predictions += (xgb_weight * offline_predictions_xgb)\n\n            zero_sum_preds = zero_sum(offline_predictions, df_valid_feats['bid_size'] + df_valid_feats['ask_size'])\n            zero_mean_preds = offline_predictions - offline_predictions.mean()\n            offline_score = mean_absolute_error(offline_predictions, df_valid_target)\n            zero_sum_score = mean_absolute_error(zero_sum_preds, df_valid_target)\n            zero_mean_score = mean_absolute_error(zero_mean_preds, df_valid_target)\n            PrintColor(f\"Offline Score {np.round(offline_score, 4)}\", color = Fore.CYAN)\n            PrintColor(f\"Zero Sum Score {np.round(zero_sum_score, 4)}\")\n            PrintColor(f\"Zero Mean Score {np.round(zero_mean_score, 4)}\", color=Fore.YELLOW)\n            \n        else:\n            # offline predictions\n            offline_predictions = []\n            zero_sum_preds = []\n            zero_mean_preds = []\n            df_valid_target = []\n            qps = []\n            cache = pd.DataFrame()\n            counter = 0\n            for dt in range(436, 481, 1):\n                for t in range(0, 550, 10):\n\n                    now_time = time.time()\n\n                    SUBMIT_TEST = pd.read_csv(INPUT_DIR / f\"stream-data/{dt}_{t}_val.csv\")\n                    df_valid_target_stream = SUBMIT_TEST[\"target\"].values\n\n                    cache = pd.concat([cache, SUBMIT_TEST], ignore_index=True, axis=0)\n                    if counter > 0:\n                        cache = cache.groupby(['stock_id', 'seconds_in_bucket']).tail(2).sort_values(by=['date_id', 'seconds_in_bucket', 'stock_id']).reset_index(drop=True)\n\n                    feat = generate_all_features(cache, global_stock_id_feats)[-len(SUBMIT_TEST):]\n                    feat = reduce_mem_usage(feat)\n\n                    if use_lgb:\n                        offline_predictions_lgb = infer_lgb_model.predict(feat)\n                    if use_cat:\n                        offline_predictions_cat = infer_cat_model.predict(feat)\n                    if use_xgb:\n                        offline_predictions_xgb = infer_xgb_model.predict(df_valid_feats[feature_name])\n\n                    offline_predictions_stream = None\n    \n                    if use_lgb:\n                        if offline_predictions_stream is None:\n                            offline_predictions_stream = (lgb_weight * offline_predictions_lgb)\n                        else:\n                            offline_predictions_stream += (lgb_weight * offline_predictions_lgb)\n\n                    if use_cat:\n                        if offline_predictions_stream is None:\n                            offline_predictions_stream = (cat_weight * offline_predictions_cat)\n                        else:\n                            offline_predictions_stream += (cat_weight * offline_predictions_cat)\n\n                    if use_xgb:\n                        if offline_predictions_stream is None:\n                            offline_predictions_stream = (xgb_weight * offline_predictions_xgb)\n                        else:\n                            offline_predictions_stream += (xgb_weight * offline_predictions_xgb)\n\n                    zero_sum_preds_stream = zero_sum(offline_predictions_stream, SUBMIT_TEST['bid_size'] + SUBMIT_TEST['ask_size'])\n                    zero_mean_preds_stream = offline_predictions_stream - offline_predictions_stream.mean()\n\n                    if counter == 1:\n                        print(np.mean(zero_mean_preds_stream))\n\n                    counter += 1\n\n                    offline_predictions.extend(list(offline_predictions_stream))\n                    zero_sum_preds.extend(list(zero_sum_preds_stream))\n                    zero_mean_preds.extend(list(zero_mean_preds_stream))\n                    df_valid_target.extend(list(df_valid_target_stream))\n\n                    qps.append(time.time() - now_time)\n\n                    if counter % 10 == 0:\n                        print(cache.shape)\n                        print(counter, 'qps:', np.mean(qps))\n\n            offline_predictions = np.array(offline_predictions)\n            zero_sum_preds = np.array(zero_sum_preds)\n            zero_mean_preds = np.array(zero_mean_preds)\n            df_valid_target = np.array(df_valid_target)\n\n            offline_score = mean_absolute_error(offline_predictions, df_valid_target)\n            zero_sum_score = mean_absolute_error(zero_sum_preds, df_valid_target)\n            zero_mean_score = mean_absolute_error(zero_mean_preds, df_valid_target)\n            PrintColor(f\"Offline Score {np.round(offline_score, 4)}\", color = Fore.CYAN)\n            PrintColor(f\"Zero Sum Score {np.round(zero_sum_score, 4)}\")\n            PrintColor(f\"Zero Mean Score {np.round(zero_mean_score, 4)}\", color=Fore.YELLOW)\n            \nctypes.CDLL(\"libc.so.6\").malloc_trim(0);\ngc.collect();\nprint();\n","metadata":{"papermill":{"duration":0.043386,"end_time":"2023-12-17T01:30:22.688975","exception":false,"start_time":"2023-12-17T01:30:22.645589","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-18T08:33:40.765596Z","iopub.execute_input":"2023-12-18T08:33:40.765922Z","iopub.status.idle":"2023-12-18T08:33:40.900647Z","shell.execute_reply.started":"2023-12-18T08:33:40.765896Z","shell.execute_reply":"2023-12-18T08:33:40.899794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **SUBMISSION**","metadata":{}},{"cell_type":"code","source":"%%time \n\n# –ï—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —Ñ–ª–∞–≥ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ (–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è)\nif inference_flag == 3:\n    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≥–ª–æ–±–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ –ø–µ—Ä–≤–æ–º—É –±–ª–æ–∫—É\n    global_stock_id_feats = {\n        \"median_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].median() + df_train.groupby(\"stock_id\")[\"ask_size\"].median(),\n        \"std_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].std() + df_train.groupby(\"stock_id\")[\"ask_size\"].std(),\n        \"ptp_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].max() - df_train.groupby(\"stock_id\")[\"bid_size\"].min(),\n        \"median_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].median() + df_train.groupby(\"stock_id\")[\"ask_price\"].median(),\n        \"std_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].std() + df_train.groupby(\"stock_id\")[\"ask_price\"].std(),\n        \"ptp_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].max() - df_train.groupby(\"stock_id\")[\"ask_price\"].min(),\n    };\n    \n    # –û—Ç–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ date_id –∏ —É–º–µ–Ω—å—à–µ–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏\n    df_train_debug = df_train[df_train.date_id >= 470].reset_index(drop=True)\n    df_train_debug = reduce_mem_usage(df_train_debug)\n    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ—Ç–ª–∞–¥–æ—á–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö\n    df_train_feats = generate_all_features(df_train_debug, global_stock_id_feats)\n    df_train_feats = reduce_mem_usage(df_train_feats)\n    # –£–¥–∞–ª–µ–Ω–∏–µ –ª–∏—à–Ω–∏—Ö –∫–æ–ª–æ–Ω–æ–∫ –∏–∑ –Ω–∞–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n    df_train_feats = df_train_feats.drop(columns=['date_id', 'time_id', \"row_id\", \"dow\", \"target\"], errors=\"ignore\")\n    \n    # –ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤\n    \n    if use_lgb:\n        infer_lgb_model = joblib.load(f\"/kaggle/input/optivermodels/LGBM1R_V{version}.model\");\n        display(infer_lgb_model);\n        print();\n        \n    if use_cat:\n        infer_cat_model = joblib.load(f\"/kaggle/input/optivermodels/CBR_V{version}.model\");\n        display(infer_cat_model);\n        print();\n        \n    if use_xgb:\n        infer_xgb_model = joblib.load(f\"/kaggle/input/optivermodels/XGBR_V{version}.model\");\n        display(infer_xgb_model);\n        print();\n        \n    feature_name = list(df_train_feats.columns);\n    PrintColor(f\"\\n\\n---> Selected columns = {len(feature_name)}\\n\");\n    with np.printoptions(linewidth = 160):\n        pprint(np.array(feature_name));\n    \nctypes.CDLL(\"libc.so.6\").malloc_trim(0);\ngc.collect();\nprint();","metadata":{"papermill":{"duration":13.999715,"end_time":"2023-12-17T01:30:36.722055","exception":false,"start_time":"2023-12-17T01:30:22.72234","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-18T08:33:40.90169Z","iopub.execute_input":"2023-12-18T08:33:40.901969Z","iopub.status.idle":"2023-12-18T08:33:51.626798Z","shell.execute_reply.started":"2023-12-18T08:33:40.901945Z","shell.execute_reply":"2023-12-18T08:33:51.62591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\n# –ï—Å–ª–∏ —Ñ–ª–∞–≥ is_infer —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –Ω–∞—á–∏–Ω–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞\nif is_infer:\n    has_refitted = False  # –§–ª–∞–≥, —É–∫–∞–∑—ã–≤–∞—é—â–∏–π –Ω–∞ —Ç–æ, –±—ã–ª–æ –ª–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ –ø–æ–≤—Ç–æ—Ä–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n    models_dict = {}  # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π\n    \n    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –±–∏–±–ª–∏–æ—Ç–µ–∫—É optiver2023 –∏ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Å—Ä–µ–¥—É –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è\n    import optiver2023\n    optiver2023.make_env.func_dict['__called__'] = False\n    env = optiver2023.make_env()\n    iter_test = env.iter_test()  # –ü–æ–ª—É—á–∞–µ–º –∏—Ç–µ—Ä–∞—Ç–æ—Ä –¥–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n    \n    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ–º –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞\n    counter = 0  # –°—á–µ—Ç—á–∏–∫ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∏—Ç–µ—Ä–∞—Ü–∏–π\n    next_refit_date = None  # –°–ª–µ–¥—É—é—â–∞—è –¥–∞—Ç–∞ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è\n    lgb_refit_times = 0  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –æ–±—É—á–µ–Ω–∏–π –º–æ–¥–µ–ª–∏ LightGBM\n    cat_refit_times = 0  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –æ–±—É—á–µ–Ω–∏–π –º–æ–¥–µ–ª–∏ CatBoost\n    refit_times = 0  # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –æ–±—É—á–µ–Ω–∏–π\n    \n    # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –≤ —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n    models_dict[f\"infer_lgb_{lgb_refit_times}\"] = infer_lgb_model\n    models_dict[f\"infer_cat_{cat_refit_times}\"] = infer_cat_model\n    \n    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –∏ –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞\n    qps, predictions = 0, []\n    \n    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º DataFrame'—ã –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –∫—ç—à–∞\n    prev_df = pd.DataFrame()  # –î–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —à–∞–≥–∞\n    cache = pd.DataFrame()  # –ö—ç—à –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n    date_3_target = pd.DataFrame()  # –î–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ü–µ–ª–µ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π —Å –∑–∞–¥–µ—Ä–∂–∫–æ–π –≤ 3 –¥–Ω—è\n    date_2_target = pd.DataFrame()  # –î–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ü–µ–ª–µ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π —Å –∑–∞–¥–µ—Ä–∂–∫–æ–π –≤ 2 –¥–Ω—è\n    date_target = pd.DataFrame()  # –î–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç–µ–∫—É—â–∏—Ö —Ü–µ–ª–µ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π\n\n# –í—ã–∑—ã–≤–∞–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏—è –ø–∞–º—è—Ç–∏\nctypes.CDLL(\"libc.so.6\").malloc_trim(0)\ngc.collect()\nprint()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-18T08:33:51.629806Z","iopub.execute_input":"2023-12-18T08:33:51.630174Z","iopub.status.idle":"2023-12-18T08:33:51.791198Z","shell.execute_reply.started":"2023-12-18T08:33:51.63014Z","shell.execute_reply":"2023-12-18T08:33:51.790295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \n# –ï—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω —Ä–µ–∂–∏–º –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞\nif is_infer:\n    for (test, revealed_targets, sample_prediction) in iter_test:\n        # –ï—Å–ª–∏ —ç—Ç–æ –ø–µ—Ä–≤–∞—è —Å–µ–∫—É–Ω–¥–∞ –≤ –¥–Ω–µ, –æ–±–Ω–æ–≤–ª—è–µ–º —Ü–µ–ª–∏ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –¥–Ω–µ–π\n        if test.seconds_in_bucket.iloc[0]== 0:\n            date_3_target = date_2_target\n            date_2_target = date_target\n            date_target = revealed_targets\n         # –ì–æ—Ç–æ–≤–∏–º –¥–∞–Ω–Ω—ã–µ —Ü–µ–ª–∏ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –¥–Ω—è    \n        previous_target = \\\n        date_target[[\"stock_id\", \"date_id\", \"seconds_in_bucket\", \"revealed_target\"]].\\\n        rename(columns = {\"revealed_target\": \"prev_1_target\"});\n        # –ü—ã—Ç–∞–µ–º—Å—è –≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —Ü–µ–ª–∏ –ø—Ä–µ–¥–ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –¥–Ω—è, –∏–Ω–∞—á–µ –∑–∞–ø–æ–ª–Ω—è–µ–º NaN\n        try:\n            previous_2_target = \\\n            date_2_target[[\"stock_id\", \"date_id\", \"seconds_in_bucket\", \"revealed_target\"]].\\\n            rename(columns = {\"revealed_target\": \"prev_2_target\"});\n            previous_2_target[\"date_id\"] = previous_2_target[\"date_id\"] + 1;\n        except:\n            previous_2_target = date_target[[\"stock_id\", \"date_id\", \"seconds_in_bucket\"]];\n            previous_2_target[\"prev_2_target\"] = np.nan;\n         # –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ –¥–ª—è —Ü–µ–ª–∏ —Ç—Ä–µ—Ç—å–µ–≥–æ –¥–Ω—è –Ω–∞–∑–∞–¥   \n        try:\n            previous_3_target = \\\n            date_3_target[[\"stock_id\", \"date_id\", \"seconds_in_bucket\", \"revealed_target\"]].\\\n            rename(columns = {\"revealed_target\": \"prev_3_target\"});\n            previous_3_target[\"date_id\"] = previous_3_target[\"date_id\"] + 2;\n        except:\n            previous_3_target = date_target[[\"stock_id\", \"date_id\", \"seconds_in_bucket\"]];\n            previous_3_target[\"prev_3_target\"] = np.nan;\n            \n         # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ —Ü–µ–ª—è–º–∏\n        SUBMIT_TEST = test.merge(previous_target, on = [\"stock_id\", \"date_id\", \"seconds_in_bucket\"], how = \"left\");\n        SUBMIT_TEST = SUBMIT_TEST.merge(previous_2_target, on = [\"stock_id\", \"date_id\", \"seconds_in_bucket\"], how = \"left\");\n        SUBMIT_TEST = SUBMIT_TEST.merge(previous_3_target, on = [\"stock_id\", \"date_id\", \"seconds_in_bucket\"], how = \"left\");\n        SUBMIT_TEST[\"prev_1_target\"] = SUBMIT_TEST[\"prev_1_target\"].astype('float');\n        SUBMIT_TEST[\"prev_2_target\"] = SUBMIT_TEST[\"prev_2_target\"].astype('float');\n        SUBMIT_TEST[\"prev_3_target\"] = SUBMIT_TEST[\"prev_3_target\"].astype('float');\n        # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫\n        columns_given = ['seconds_in_bucket', 'imbalance_size',\n                         'imbalance_buy_sell_flag', 'reference_price', 'matched_size',\n                         'far_price', 'near_price', 'bid_price', 'bid_size',\n                         'ask_price', 'ask_size', 'wap'\n                        ];\n        SUBMIT_TEST[columns_given] = SUBMIT_TEST[columns_given].astype('float');\n        \n        if test.seconds_in_bucket.iloc[0]== 0:\n            curr_date = test.date_id.iloc[0]\n            try:\n                curr_date = int(curr_date)\n            except:\n                pass\n            # –ï—Å–ª–∏ —ç—Ç–æ –ø–µ—Ä–≤–∞—è —Å–µ–∫—É–Ω–¥–∞ –¥–Ω—è, –∏ –¥–∞—Ç–∞ –±–æ–ª—å—à–µ –∏–ª–∏ —Ä–∞–≤–Ω–∞ 482, –æ–±–Ω–æ–≤–ª—è–µ–º —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö\n            if curr_date >= 482:\n      \n                to_concat = \\\n                date_target[[\"stock_id\", \"date_id\", \"seconds_in_bucket\", \"revealed_target\"]].\\\n                rename(columns = {\"revealed_target\": \"target\"});\n                to_concat[\"date_id\"] = to_concat[\"date_id\"] - 1;\n                prev_df = \\\n                prev_df.merge(to_concat, on = [\"stock_id\", \"date_id\", \"seconds_in_bucket\"], how = \"left\");\n                prev_df[\"target\"] = prev_df[\"target\"].astype('float');\n                df_train = pd.concat([df_train, prev_df]).reset_index(drop=True);\n                \n                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π –¥–∞—Ç—ã, —á—Ç–æ–±—ã –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—Ç–∏—Ç—å –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏\n                df_train = df_train[df_train.date_id >= curr_date - wd_refits].dropna(subset=[\"target\"]).reset_index(drop=True)\n\n            prev_df = pd.DataFrame();\n            if is_refit:\n                if (next_refit_date is None and test.currently_scored.iloc[0] == True):\n                    next_refit_date = curr_date;\n\n                if curr_date == next_refit_date:\n                    # –ò—Å–ø–æ–ª—å–∑—É—è —Ä–∞—Å–∫—Ä—ã—Ç—É—é —Ü–µ–ª—å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–≥–æ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞\n                    if curr_date >= 482:\n                        global_stock_id_feats = {\n                            \"median_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].median() + df_train.groupby(\"stock_id\")[\"ask_size\"].median(),\n                            \"std_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].std() + df_train.groupby(\"stock_id\")[\"ask_size\"].std(),\n                            \"ptp_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].max() - df_train.groupby(\"stock_id\")[\"bid_size\"].min(),\n                            \"median_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].median() + df_train.groupby(\"stock_id\")[\"ask_price\"].median(),\n                            \"std_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].std() + df_train.groupby(\"stock_id\")[\"ask_price\"].std(),\n                            \"ptp_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].max() - df_train.groupby(\"stock_id\")[\"ask_price\"].min(),\n                        };\n                        \n                        PrintColor(\"\\nRefitting Feature Generation in progress\");\n                        df_train              = reduce_mem_usage(df_train);\n                        df_train_feats_refit  = generate_all_features(df_train, global_stock_id_feats);\n                        df_train_feats_refit  = reduce_mem_usage(df_train_feats_refit);\n                        df_train_refit_target = df_train[\"target\"];\n                        # –õ–æ–≥–∏–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π\n                        if refit_times == 0 or refit_times % 2 == 0:\n                            lgb_refit_times += 1;\n                            lgb_refit_params = \\\n                            {'objective'              : 'mae', \n                             'random_state'           : 42,\n                             'device'                 : 'gpu',\n                             'boosting_type'          : 'gbdt', \n                             'learning_rate'          : 0.015, \n                             'max_depth'              : 12, \n                             'n_estimators'           : 2250, \n                             'num_leaves'             : 300, \n                             'reg_alpha'              : 0.005, \n                             'reg_lambda'             : 0.001, \n                             'colsample_bytree'       : 0.6, \n                             'subsample'              : 0.875, \n                             'min_child_samples'      : 128,\n                             'verbose'                : -1,\n                            };\n                        \n                            print();\n                            PrintColor(\"Refitting in progress\");\n                            PrintColor(\"---> Refit LGB Params\", color=Fore.MAGENTA);\n                            print(lgb_refit_params);\n                            lgb_refit_model = lgb.LGBMRegressor(**lgb_refit_params);\n                            lgb_refit_model.fit(df_train_feats_refit[feature_name], df_train_refit_target);\n                            PrintColor(\"Refitting Done!\");\n                            models_dict[f\"infer_lgb_{lgb_refit_times}\"] = lgb_refit_model;\n                            print();\n                        \n                        if refit_times == 0 or refit_times % 2 == 1:\n                            cat_refit_times += 1;\n                            cat_refit_params = {'iterations'    : 5100, \n                                                'learning_rate' : 0.2774258427582013, \n                                                'depth'         : 10, \n                                                'l2_leaf_reg'   : 25.205435098066893, \n                                                'bootstrap_type': 'Bernoulli', \n                                                'subsample'     : 0.9405735849013803, \n                                                'loss_function' : 'MAE', \n                                                'eval_metric'   : 'MAE', \n                                                'metric_period' : 1000, \n                                                'task_type'     : 'GPU', \n                                                'allow_writing_files': False, \n                                                'random_state'       : 42,\n                                               };\n\n                            PrintColor(\"---> Refit CAT Params\", color=Fore.MAGENTA);\n                            print(cat_refit_params);\n                            cat_refit_model = CatBoostRegressor(**cat_refit_params);\n                            cat_refit_model.fit(df_train_feats_refit[feature_name], df_train_refit_target, verbose = 0);\n                            PrintColor(\"Refitting Done!\");\n                            models_dict[f\"infer_cat_{cat_refit_times}\"] = cat_refit_model;\n                            print();\n                            \n                        if refit_times == 0: \n                            refit_times += 2;\n                        else: \n                            refit_times += 1;  \n                        has_refitted = True;\n                    \n                    if refit_times < nb_refits: \n                        next_refit_date += freq_refits;               \n         \n        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –º–æ–¥–µ–ª–∏ –∏ –≤—ã–ø–æ–ª–Ω—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n        # –õ–æ–≥–∏–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–æ–¥–µ–ª–µ–π –∏ –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è        \n        prev_df = \\\n        pd.concat([prev_df, SUBMIT_TEST.drop(columns = [\"currently_scored\"])]).\\\n        reset_index(drop=True);\n        cache = pd.concat([cache, SUBMIT_TEST], ignore_index=True, axis=0);\n        \n        if counter > 0:\n            cache = \\\n            cache.groupby(['stock_id']).\\\n            tail(100).\\\n            sort_values(by=['date_id', 'seconds_in_bucket', 'stock_id']).reset_index(drop=True);\n            \n        if test.currently_scored.iloc[0]== False and (test.seconds_in_bucket.iloc[0] != 540 or test.date_id.iloc[0]!= 480):\n            sample_prediction['target'] = 0;\n            env.predict(sample_prediction);\n            counter += 1;\n            continue\n            \n        feat = generate_all_features(cache, global_stock_id_feats)[-len(test):];\n        feat = feat[feature_name];\n        \n        # Collating single model predictions:-        \n        lgb_prediction = None;\n        if has_refitted:\n            lgb_prediction = models_dict[f\"infer_lgb_{lgb_refit_times}\"].predict(feat);\n        else:\n            lgb_prediction = infer_lgb_model.predict(feat);\n   \n        cat_prediction = None;\n        if has_refitted:\n            cat_prediction = models_dict[f\"infer_cat_{cat_refit_times}\"].predict(feat);\n        else:\n            cat_prediction = infer_cat_model.predict(feat);\n\n        # Ensembling predictions:-      \n        ensemble_prediction = None\n        if ensemble_prediction is None:\n            ensemble_prediction = (lgb_weight * lgb_prediction);\n        else:\n            ensemble_prediction += (lgb_weight * lgb_prediction);\n\n        if ensemble_prediction is None:\n            ensemble_prediction = (cat_weight * cat_prediction);\n        else:\n            ensemble_prediction += (cat_weight * cat_prediction);\n\n        # Post-processing ensemble predictions:-          \n        if postprocess == \"zero_mean\":\n            ensemble_prediction = ensemble_prediction - np.mean(ensemble_prediction);\n        elif postprocess == \"zero_sum\":\n            ensemble_prediction = zero_sum(ensemble_prediction, test['bid_size'] + test['ask_size']);\n        else:\n            pass;\n          \n        # Making API predictions:-           \n        sample_prediction['target'] = ensemble_prediction;\n        env.predict(sample_prediction);\n        counter += 1;\n      # –í—ã–≤–æ–¥–∏–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ø–æ—Å–ª–µ –≤–æ–∑–º–æ–∂–Ω–æ–≥–æ –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è   \n    PrintColor(f\"\\n\\nSubmission file after refits\\n\");\n    display(sample_prediction.head(10));\n    print();\n    \nctypes.CDLL(\"libc.so.6\").malloc_trim(0);\ngc.collect();\nprint();   ","metadata":{"execution":{"iopub.status.busy":"2023-12-18T08:33:51.792803Z","iopub.execute_input":"2023-12-18T08:33:51.79309Z","iopub.status.idle":"2023-12-18T08:34:00.98009Z","shell.execute_reply.started":"2023-12-18T08:33:51.793064Z","shell.execute_reply":"2023-12-18T08:34:00.979141Z"},"trusted":true},"execution_count":null,"outputs":[]}]}